{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7cc9dc0b",
      "metadata": {
        "id": "7cc9dc0b"
      },
      "source": [
        "# 🔍 Assignment: Build a Context-Aware LLM Agent Using LangChain\n",
        "\n",
        "##  Objective\n",
        "Design and implement your **own LLM-powered agent** using the LangChain ecosystem. This agent should:\n",
        "- Use at least **one tool**\n",
        "- Incorporate **function-calling**\n",
        "- Integrate **LangSmith** for observability\n",
        "- Implement a **fallback mechanism**\n",
        "- Bonus: Use the **Agentic** library to define a clear multi-step workflow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ca463ac",
      "metadata": {
        "id": "7ca463ac"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "##  Your Task\n",
        "- Choose a use case (e.g., travel planner, medical assistant, customer support bot, product recommender, etc.)\n",
        "- Build a custom tool (e.g., API wrapper, knowledge lookup, calculator)\n",
        "- Use LangChain agents to manage interaction\n",
        "- Integrate LangSmith to track runs\n",
        "- Handle failure gracefully with a fallback approach\n",
        "- Optionally add structured workflows with Agentic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "956bf8b3",
      "metadata": {
        "id": "956bf8b3"
      },
      "outputs": [],
      "source": [
        "!pip install dotenv langchain pydantic langchain_openai\n",
        "!pip install -U langchain-community\n",
        "!pip install chromadb\n",
        "!pip install google-search-results\n",
        "!pip install serpapi\n",
        "!pip install openweathermap\n",
        "!pip install groq\n",
        "!pip install langsmith\n",
        "!pip install ChatGroq\n",
        "!pip install -U langchain-groq\n",
        "!pip install langchain-mistralai\n",
        "!pip install langchain-core langsmith"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "751e9fa6",
      "metadata": {
        "id": "751e9fa6"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import io\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "from google.colab import userdata\n",
        "from contextlib import redirect_stdout\n",
        "from enum import Enum\n",
        "from typing import Annotated, Dict, List, Optional\n",
        "import requests\n",
        "from google.colab import userdata\n",
        "from groq import Groq\n",
        "from langchain.agents import (\n",
        "    AgentExecutor,\n",
        "    AgentType,\n",
        "    create_tool_calling_agent,\n",
        "    initialize_agent,\n",
        ")\n",
        "from langchain.callbacks import StdOutCallbackHandler\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.tools import tool\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_mistralai import ChatMistralAI\n",
        "from langsmith.run_helpers import traceable\n",
        "from pydantic import BaseModel, Field\n",
        "from serpapi.google_search import GoogleSearch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c817f3c7",
      "metadata": {
        "id": "c817f3c7"
      },
      "source": [
        "##  Step 2: Set Up Keys\n",
        " You’ll need:\n",
        "- An OpenAI API key (for LLM calls)/ Groq API\n",
        "- A LangSmith API key (for logging and observability)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "groqKey = userdata.get('groq')\n",
        "langsmithKey = userdata.get('Langsmith')\n",
        "tavilyKey = userdata.get('tavily')\n",
        "serpKey = userdata.get('serp')\n",
        "openweatherKey = userdata.get('openweather')\n",
        "mistralKey = userdata.get('mistral')"
      ],
      "metadata": {
        "id": "5oJOyLtu6lA6"
      },
      "id": "5oJOyLtu6lA6",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2eb2c451",
      "metadata": {
        "id": "2eb2c451"
      },
      "source": [
        "##  Step 3: Define Custom Tools\n",
        " Build at least one tool (e.g., API, calculator, mock database lookup). Use decorators or `Tool` wrappers."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enum for allowed event date ranges\n",
        "\n",
        "class EventDate(str, Enum):\n",
        "  \"\"\"\n",
        "  Represents predefined date ranges for event queries.\n",
        "  The string values correspond to how they might be interpreted by an underlying API\n",
        "  or internal logic.\n",
        "  \"\"\"\n",
        "  TODAY = \"today\"\n",
        "  TOMORROW = \"tomorrow\"\n",
        "  THIS_WEEK = \"week\"\n",
        "  THIS_WEEKEND = \"weekend\"\n",
        "  NEXT_WEEK = \"next_week\"\n",
        "  THIS_MONTH = \"month\"\n",
        "  NEXT_MONTH = \"next_month\"\n",
        "\n",
        "# --- Define the Events Query Pydantic Model ---\n",
        "\n",
        "class EventsQuery(BaseModel):\n",
        "  \"\"\"\n",
        "  A Pydantic model for querying events with structured parameters.\n",
        "  This model defines the expected input for a function that lists events.\n",
        "  \"\"\"\n",
        "\n",
        "  event_type: str = Field(...,description=\"What type of event are you looking for? Example: Party,food,tourism, etc.\")\n",
        "  event_date: EventDate = Field(\n",
        "      ...,\n",
        "      description=(\n",
        "          \"The specific date range for the events. \"\n",
        "          \"Must be one of the predefined values: \"\n",
        "          f\"{', '.join([f'`{e.value}`' for e in EventDate])}.\"\n",
        "      )\n",
        "  )\n",
        "  location: str = Field(...,description=\"The location of the event. This field is required.\")\n",
        "\n",
        "\n",
        "@tool(\"event_getter_tool\", args_schema=EventsQuery, description=\"Fetches specific events at a given time period from now in a given location\")\n",
        "def get_events_from_serpapi(event_type: str, event_date: EventDate, location: str) -> List[Dict]:\n",
        "  \"\"\"\n",
        "  Fetches events using SerpAPI based on the provided parameters.\n",
        "  \"\"\"\n",
        "\n",
        "  #print(f\"\\n[TOOL CALL: get_events] Calling SerpAPI for: '{event_type} in {location}' on date: {event_date.value}...\")\n",
        "\n",
        "  htichips_list = [f\"date:{event_date.value}\"]\n",
        "  htichips_param = \",\".join(htichips_list)\n",
        "\n",
        "  main_query = f\"{event_type} in {location}\"\n",
        "\n",
        "  #Parameters for the google search\n",
        "  params = {\n",
        "      \"api_key\": serpKey,\n",
        "      \"engine\": \"google_events\",\n",
        "      \"q\": main_query,\n",
        "      \"hl\": \"en\",\n",
        "      \"gl\": \"us\",\n",
        "      \"htichips\": htichips_param,\n",
        "  }\n",
        "\n",
        "  try:\n",
        "    search = GoogleSearch(params)\n",
        "    results = search.get_dict()\n",
        "    events_results = results.get(\"events_results\", [])\n",
        "    events_results = events_results[:1] # Limit results for now to minimize tokens\n",
        "\n",
        "    if events_results:\n",
        "        print(f\"[TOOL SUCCESS] Fetched {len(events_results)} events for '{event_type}' in {location}.\")\n",
        "    else:\n",
        "        print(f\"[TOOL INFO] No events found for '{event_type}' in {location} from SerpAPI.\")\n",
        "    return events_results\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"[TOOL ERROR] An error occurred during SerpAPI call: {e}\")\n",
        "    return []"
      ],
      "metadata": {
        "id": "QjUwCsPbV6bU"
      },
      "id": "QjUwCsPbV6bU",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AirPollutionQuery(BaseModel):\n",
        "  \"\"\"\n",
        "  A Pydantic model for querying current air pollution data for a city.\n",
        "  \"\"\"\n",
        "  city: str = Field(..., description=\"The single city name for which to get air pollution data.\")\n",
        "\n",
        "@tool(\"get_current_air_pollution\", args_schema=AirPollutionQuery,\n",
        "  description=\"Fetches the most recent air pollution data (AQI, CO, NO2, O3, PM2.5, etc.) for a specified city.\")\n",
        "def get_current_air_pollution_data_by_city(city: str) -> Dict:\n",
        "  \"\"\"\n",
        "  Fetches the most recent air pollution data for a given city name.\n",
        "  \"\"\"\n",
        "\n",
        "  #print(f\"\\n[TOOL CALL: get_current_air_pollution] Getting air pollution for city: {city}...\")\n",
        "\n",
        "  # --- Step 1: Get Latitude and Longitude using Geocoding API ---\n",
        "  geocode_url = f'http://api.openweathermap.org/geo/1.0/direct?q={city}&limit=1&appid={openweatherKey}'\n",
        "  lat = None\n",
        "  lon = None\n",
        "\n",
        "  try:\n",
        "    geocode_response = requests.get(geocode_url)\n",
        "    geocode_response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)\n",
        "    geocode_data = geocode_response.json()\n",
        "\n",
        "    if geocode_data and len(geocode_data) > 0:\n",
        "      lat = geocode_data[0].get('lat')\n",
        "      lon = geocode_data[0].get('lon')\n",
        "      print(f\"Found coordinates for {city}: Lat={lat}, Lon={lon}\")\n",
        "    else:\n",
        "      print(f\"[TOOL ERROR] Could not find coordinates for city: {city}.\")\n",
        "      return {\"error\": f\"Could not find coordinates for city: {city}. Please check the city name.\"}\n",
        "\n",
        "  except requests.exceptions.RequestException as req_err:\n",
        "      print(f'[TOOL ERROR] Geocoding API request error occurred: {req_err}')\n",
        "      return {\"error\": f\"Geocoding API error: {req_err}\"}\n",
        "  except json.JSONDecodeError:\n",
        "      print('[TOOL ERROR] Error: Could not decode JSON from Geocoding API response.')\n",
        "      return {\"error\": \"Invalid JSON response from Geocoding API.\"}\n",
        "  except Exception as e:\n",
        "      print(f'[TOOL ERROR] An unexpected error occurred during geocoding: {e}')\n",
        "      return {\"error\": f\"Unexpected geocoding error: {e}\"}\n",
        "\n",
        "  # --- Step 2: Get Current Air Pollution Data using obtained coordinates ---\n",
        "\n",
        "  if lat is None or lon is None:\n",
        "      print(\"[TOOL ERROR] Latitude or Longitude not available after geocoding, cannot fetch air pollution data.\")\n",
        "      return {\"error\": \"Latitude or Longitude not available to fetch air pollution data.\"}\n",
        "\n",
        "  pollution_url = (\n",
        "      f\"http://api.openweathermap.org/data/2.5/air_pollution?\"\n",
        "      f\"lat={lat}&lon={lon}&appid={openweatherKey}\"\n",
        "  )\n",
        "\n",
        "  try:\n",
        "    pollution_response = requests.get(pollution_url)\n",
        "    pollution_response.raise_for_status()\n",
        "    pollution_data = pollution_response.json()\n",
        "\n",
        "    if pollution_data and 'list' in pollution_data and len(pollution_data['list']) > 0:\n",
        "\n",
        "      most_recent_data = pollution_data['list'][0]\n",
        "      timestamp = most_recent_data.get('dt')\n",
        "\n",
        "      if timestamp:\n",
        "        dt_object = datetime.datetime.fromtimestamp(timestamp, datetime.timezone.utc)\n",
        "        most_recent_data['datetime_utc'] = dt_object.isoformat()\n",
        "\n",
        "      print(f\"[TOOL SUCCESS] Fetched air pollution for {city}.\")\n",
        "\n",
        "      return most_recent_data\n",
        "\n",
        "    else:\n",
        "      print(\"[TOOL INFO] No current air pollution data found for this location or unexpected response format.\")\n",
        "      return {\"error\": \"No air pollution data found or unexpected response.\"}\n",
        "\n",
        "  except requests.exceptions.RequestException as req_err:\n",
        "    print(f'[TOOL ERROR] Air Pollution API request error occurred: {req_err}')\n",
        "    return {\"error\": f\"Air Pollution API error: {req_err}\"}\n",
        "  except json.JSONDecodeError:\n",
        "    print('[TOOL ERROR] Error: Could not decode JSON from Air Pollution API response.')\n",
        "    return {\"error\": \"Invalid JSON response from Air Pollution API.\"}\n",
        "  except Exception as e:\n",
        "    print(f'[TOOL ERROR] An unexpected error occurred during air pollution data fetch: {e}')\n",
        "    return {\"error\": f\"Unexpected air pollution fetch error: {e}\"}"
      ],
      "metadata": {
        "id": "n-1LOTZi7KNz"
      },
      "id": "n-1LOTZi7KNz",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_tools = [\n",
        "    get_events_from_serpapi,\n",
        "    get_current_air_pollution_data_by_city\n",
        "    ]"
      ],
      "metadata": {
        "id": "szsIs-U6HzDO"
      },
      "id": "szsIs-U6HzDO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "6d6cc178",
      "metadata": {
        "id": "6d6cc178"
      },
      "source": [
        "##  Step 4: Enable Function-Calling\n",
        " Define structured functions for your agent to call. Use `openai.FunctionsAgent` or LangChain's `OPENAI_FUNCTIONS` agent type."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@traceable(name=\"VacationPlanningRun\")\n",
        "def run(input_text: str):\n",
        "  f = io.StringIO()\n",
        "  with redirect_stdout(f):  # Suppress stdout temporarily\n",
        "      result = agent_executor.invoke({\"input\": input_text})\n",
        "  return result[\"output\"]"
      ],
      "metadata": {
        "id": "Wm3Oe3IAIACr"
      },
      "id": "Wm3Oe3IAIACr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGroq(\n",
        "        model=\"llama3-70b-8192\", # Recommended Groq model for tool use\n",
        "        temperature=0,\n",
        "        max_retries=3,\n",
        "        api_key=groqKey\n",
        "    )\n",
        "\n",
        "llm_with_tools = llm.bind_tools(agent_tools)\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant that helps people find events in a city and check for air pollution.\"),\n",
        "        MessagesPlaceholder(variable_name=\"chat_history\", optional=True), # For conversational memory\n",
        "        (\"human\", \"{input}\"),\n",
        "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),            # Agent's internal thoughts and tool outputs\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "z2VevKrNscif"
      },
      "id": "z2VevKrNscif",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1c277f35",
      "metadata": {
        "id": "1c277f35"
      },
      "source": [
        "##  Step 5: Integrate LangSmith\n",
        " Wrap your LLM or agent with LangSmith to observe performance and execution flows."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = langsmithKey                         # Update with your API key\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "project_name = \"Assignment_2\"                                          # Update with your project name\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = project_name\n",
        "os.environ[\"GROQ_API_KEY\"] = groqKey"
      ],
      "metadata": {
        "id": "6WkWENR5Lpco"
      },
      "id": "6WkWENR5Lpco",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "df221059",
      "metadata": {
        "id": "df221059"
      },
      "source": [
        "##  Step 6: Fallback Strategy\n",
        " Define a fallback agent or tool to be used when the main tool or agent fails."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a fallback LLM using ChatMistralAI\n",
        "fallback_llm = ChatMistralAI(\n",
        "    model=\"mistral-small-2501\",\n",
        "    temperature=0,\n",
        "    api_key=mistralKey\n",
        ")\n",
        "\n",
        "llm_with_fallbacks = llm_with_tools.with_fallbacks([fallback_llm])"
      ],
      "metadata": {
        "id": "N6rCNRgNL3zQ"
      },
      "id": "N6rCNRgNL3zQ",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Create the tool-calling agent\n",
        "agent = create_tool_calling_agent(llm_with_fallbacks, agent_tools, prompt)\n",
        "\n",
        "memory = ConversationBufferMemory(\n",
        "        memory_key=\"chat_history\",\n",
        "        output_key=\"output\",\n",
        "        return_messages=True       # Return history as a list of message objects\n",
        "    )\n",
        "\n",
        "# 8. Create an AgentExecutor to run the agent\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=agent,\n",
        "    tools=agent_tools,            # Provide the list of tools to the executor\n",
        "    verbose=False,                # See the agent's thinking process\n",
        "    handle_parsing_errors=True,\n",
        "    memory=memory,\n",
        "    return_intermediate_steps=True\n",
        ")"
      ],
      "metadata": {
        "id": "EX6DJ0yKqvVB"
      },
      "id": "EX6DJ0yKqvVB",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(run(\"Find me events in Tokyo for next month\"))"
      ],
      "metadata": {
        "id": "g5C3qYMr1rOv",
        "outputId": "45a6aba9-22a9-4e3c-9976-156a8a79b26c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "g5C3qYMr1rOv",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are the events in Tokyo for next month:\n",
            "\n",
            "* Baki Exhibition: June 13, 10:30 AM – July 1, 9:00 PM GMT+9 at SHIBUYA TSUTAYA, Q Front, B2F-8F 21-6 Udagawacho, Shibuya, Tokyo, Japan.\n",
            "\n",
            "Let me know if you need more information or if there's anything else I can help you with!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc5e006f",
      "metadata": {
        "id": "dc5e006f"
      },
      "source": [
        "##  (Bonus) Step 7: Define a Workflow using Agentic\n",
        " Use the `agentic` library to define a step-by-step flow your agent follows."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "000eef2b",
      "metadata": {
        "id": "000eef2b"
      },
      "source": [
        " Submission Checklist\n",
        "- [ ] Agent runs end-to-end on your chosen use case\n",
        "- [ ] At least one custom tool is integrated\n",
        "- [ ] Function-calling works with tools\n",
        "- [ ] LangSmith integration logs all calls\n",
        "- [ ] Fallback logic is demonstrated\n",
        "- [ ] Bonus: Agentic workflow is defined"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10d4f245",
      "metadata": {
        "id": "10d4f245"
      },
      "source": [
        "##  Grading (100 pts )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "071c8888",
      "metadata": {
        "id": "071c8888"
      },
      "source": [
        "##  Tip\n",
        "You are free to choose **any use case** — be creative but keep your design modular and well-commented!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}